<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Search for writing and research on AI detection software from a critical pers...</title>
    <style>
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: 'Courier New', monospace;
            background: #111;
            color: #999;
            line-height: 1.6;
            padding: 40px 20px 60px;
            max-width: 680px;
            margin: 0 auto;
        }
        a { color: #888; }
        a:hover { color: #ccc; }
        .back { display: inline-block; margin-bottom: 30px; font-size: 13px; text-decoration: none; }
        .back:before { content: '← '; }
        header { margin-bottom: 40px; padding-bottom: 20px; border-bottom: 1px solid #333; }
        header h1 { color: #ccc; font-size: 20px; font-weight: normal; margin-bottom: 8px; }
        header .meta { font-size: 12px; color: #555; }
        article { color: #aaa; }
        article h1 { color: #bbb; font-size: 17px; font-weight: normal; margin: 35px 0 15px; }
        article h2 { color: #999; font-size: 15px; font-weight: normal; margin: 30px 0 12px; text-transform: lowercase; }
        article h3 { color: #777; font-size: 14px; font-weight: normal; margin: 20px 0 10px; }
        article p { margin-bottom: 16px; }
        article strong { color: #ccc; font-weight: normal; }
        article em { font-style: normal; color: #888; }

        /* Chicago-style citation styling */
        .citation { font-size: 0.75em; vertical-align: super; line-height: 0; }
        .citation a {
            color: #ff6b6b;
            text-decoration: none;
            padding: 0 1px;
            transition: color 0.2s;
        }
        .citation a:hover { color: #ff9999; text-decoration: underline; }

        /* References section */
        .references {
            margin-top: 50px;
            padding-top: 25px;
            border-top: 1px solid #333;
        }
        .references h2 {
            color: #666;
            font-size: 14px;
            margin-bottom: 20px;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        .references ol {
            list-style: none;
            padding: 0;
        }
        .references li {
            font-size: 12px;
            margin: 12px 0;
            padding-left: 30px;
            position: relative;
            line-height: 1.5;
            word-break: break-word;
        }
        .references .back-ref {
            position: absolute;
            left: 0;
            top: 0;
            color: #ff6b6b;
            text-decoration: none;
            font-size: 11px;
        }
        .references .back-ref:hover { color: #ff9999; }
        .references .cite-num {
            color: #666;
            margin-right: 8px;
        }
        .references li a:not(.back-ref) {
            color: #666;
            word-break: break-all;
        }
        .references li a:not(.back-ref):hover { color: #999; }

        footer { margin-top: 60px; padding-top: 20px; border-top: 1px solid #222; font-size: 11px; color: #444; }
        @media (max-width: 600px) {
            body { padding: 25px 15px 40px; }
            header h1 { font-size: 18px; }
        }
    </style>
</head>
<body>
    <a class="back" href="../../index.html">back</a>
    <header>
        <h1>Search for writing and research on AI detection software from a critical pers...</h1>
        <div class="meta">researched Feb 5, 2026 · dug up by sportello</div>
    </header>
    <article>
        <h1>The Critical Analysis of AI Detection Software: Unreliability, Inequity, and Threats to Student Learning</h1>
<p>This comprehensive report examines the critical limitations and harmful effects of artificial intelligence detection software in educational settings, with particular emphasis on the technical inadequacies of these tools and their demonstrably uneven impact on student learning and wellbeing. Contemporary research from 2023 through early 2026 reveals that AI detection tools, while widely adopted by educators seeking to maintain academic integrity, suffer from significant technical flaws including inconsistent accuracy rates, high false positive rates that disproportionately affect marginalized students, and fundamental limitations that make them unsuitable for high-stakes academic misconduct decisions. Beyond technical limitations, this analysis demonstrates that the deployment of these tools creates substantial psychological harms for students, undermines pedagogical relationships, and disproportionately penalizes non-native English speakers and neurodivergent learners. Rather than solving academic integrity challenges, AI detectors have created new problems within educational systems, prompting leading institutions to disable these features and prompting educators to shift toward process-focused assessment design, transparent communication about AI use, and authentic task creation that is inherently resistant to undetected AI use.</p>
<h2>Understanding AI Detection Technology: How These Tools Function and Why Their Mechanics Are Fundamentally Uneven</h2>
<p>Artificial intelligence detection software operates on statistical and probabilistic principles that differ fundamentally across different tools, making consistency and reliability nearly impossible to achieve.<sup class="citation"><a href="#ref-9" id="cite-9">9</a>,<a href="#ref-15" id="cite-15">15</a>,<a href="#ref-18" id="cite-18">18</a></sup> To understand the critical limitations of these systems, it is essential to first understand how they are designed to function. AI detectors typically analyze written work using multiple linguistic features to estimate the likelihood that a large language model generated the content, relying heavily on metrics such as perplexity and burstiness to make these determinations.<sup class="citation"><a href="#ref-9" id="cite-9">9</a>,<a href="#ref-15" id="cite-15">15</a>,<a href="#ref-18" id="cite-18">18</a></sup> Perplexity measures how predictable the sequence of words is in a text, with the underlying assumption that AI language models tend to produce more predictable text with lower perplexity because they function by calculating probabilities about which word should come next in a sequence.<sup class="citation"><a href="#ref-18" id="cite-18">18</a></sup> Burstiness, by contrast, measures the variation in sentence length and structural complexity throughout a document, based on the observation that human writers tend to vary their sentence structures for rhetorical effect and reader engagement, while AI models may produce more uniform sentence patterns.<sup class="citation"><a href="#ref-18" id="cite-18">18</a>,<a href="#ref-21" id="cite-21">21</a></sup> Together, these metrics form the theoretical foundation for many commercially available detection tools.<sup class="citation"><a href="#ref-18" id="cite-18">18</a></sup></p>
<p>However, the critical problem with this approach is immediately apparent when examining how different tools apply these same principles: they do not reach the same conclusions about the same text, and there is no universal standard for how much perplexity or burstiness constitutes AI-generated versus human-generated work.<sup class="citation"><a href="#ref-30" id="cite-30">30</a>,<a href="#ref-37" id="cite-37">37</a></sup> A study conducted in 2025 demonstrated that when different detection tools analyzed identical content, they produced substantially different results, with some tools flagging the same essay as 10% AI-generated while others flagged it as 81% AI-generated.<sup class="citation"><a href="#ref-40" id="cite-40">40</a></sup> This inconsistency is not a minor discrepancy but rather a fundamental indictment of the entire approach.<sup class="citation"><a href="#ref-30" id="cite-30">30</a></sup> The reason for this variation lies in how individual tools are trained and what datasets they use to learn the difference between human and AI-generated text.<sup class="citation"><a href="#ref-30" id="cite-30">30</a></sup> Each AI detector is trained on distinct datasets, which may have different labeling standards, different proportions of human versus AI content, and different types of writing styles.<sup class="citation"><a href="#ref-30" id="cite-30">30</a></sup> Some tools are trained primarily on academic writing, while others include a broader range of content including blogs, social media, and news articles, leading to fundamentally different baseline expectations for what human writing looks like.<sup class="citation"><a href="#ref-30" id="cite-30">30</a></sup></p>
<p>Additionally, the field of AI detection is characterized by what researchers call "contaminated training data," a problem that undermines the reliability of all existing detectors.<sup class="citation"><a href="#ref-30" id="cite-30">30</a></sup> Because AI-generated content has become increasingly ubiquitous online, many of the datasets used to train detection tools contain text that was supposedly written by humans but actually includes substantial AI contributions.<sup class="citation"><a href="#ref-30" id="cite-30">30</a></sup> Wikipedia articles, for instance, have increasingly incorporated AI-generated content, yet detection tools may treat these as examples of purely human writing, leading them to learn distorted patterns about what human writing actually looks like.<sup class="citation"><a href="#ref-30" id="cite-30">30</a></sup> This contamination of training data is particularly problematic because it means that detection tools are not actually learning to distinguish between human and AI writing, but rather learning an increasingly blurred distinction that reflects the current state of the internet rather than any meaningful difference between how humans and machines write.<sup class="citation"><a href="#ref-30" id="cite-30">30</a></sup></p>
<p>The technical mechanics of detection also reveal fundamental vulnerabilities that make these tools fundamentally unsuitable for use in high-stakes academic contexts. The industry has been locked in what researchers describe as an "arms race" with AI-generation technology, where as language models become more sophisticated and capable of producing increasingly human-like text, detection tools must constantly update and adapt their approaches.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-21" id="cite-21">21</a>,<a href="#ref-26" id="cite-26">26</a></sup> In January 2025, an independent study found that AI detectors remain "consistently inconsistent," sometimes achieving accuracy in certain conditions but delivering different scores on the exact same files in subsequent checks.<sup class="citation"><a href="#ref-21" id="cite-21">21</a></sup> This lack of consistency undermines any claim that these tools are reliable measures of authorship.<sup class="citation"><a href="#ref-13" id="cite-13">13</a>,<a href="#ref-21" id="cite-21">21</a></sup> Some researchers have noted that paraphrasing AI-generated text—running it through another language model with instructions to rephrase it in different words while preserving meaning—reduces detection accuracy dramatically.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-21" id="cite-21">21</a>,<a href="#ref-51" id="cite-51">51</a></sup> One study demonstrated that feeding AI-generated text through a paraphrasing tool reduced detection accuracy by over 50%, suggesting that any motivated student can defeat these detection systems with minimal effort.<sup class="citation"><a href="#ref-21" id="cite-21">21</a></sup></p>
<h2>The Unreliability Problem: Technical Limitations and Inconsistencies Across Detection Platforms</h2>
<p>The fundamental unreliability of AI detection tools represents perhaps the most critical problem with their continued use in educational settings.<sup class="citation"><a href="#ref-3" id="cite-3">3</a>,<a href="#ref-10" id="cite-10">10</a>,<a href="#ref-11" id="cite-11">11</a>,<a href="#ref-27" id="cite-27">27</a></sup> While companies marketing these tools make bold claims about accuracy rates—with GPTZero claiming 99% accuracy, QuillBot claiming 80-99%, and Polygraf AI claiming 99% accuracy—independent research consistently reveals that these claims are either misleading or reflect performance only in highly controlled laboratory settings that do not reflect real-world academic writing.<sup class="citation"><a href="#ref-1" id="cite-1">1</a>,<a href="#ref-6" id="cite-6">6</a>,<a href="#ref-10" id="cite-10">10</a>,<a href="#ref-11" id="cite-11">11</a>,<a href="#ref-37" id="cite-37">37</a></sup> When researchers have independently tested these same tools using diverse writing samples that reflect actual student work, the results are substantially more modest and highly variable.<sup class="citation"><a href="#ref-3" id="cite-3">3</a>,<a href="#ref-27" id="cite-27">27</a></sup></p>
<p>A comprehensive study published in 2024 that examined three widely-used detection tools found remarkable inconsistency in how these tools perform across different types of content.<sup class="citation"><a href="#ref-27" id="cite-27">27</a></sup> When testing ZeroGPT, Phrasly AI, and Grammarly on five different conditions of text ranging from purely human-written to purely AI-generated, the tools showed "statistically significant differences" in their ability to distinguish these categories, but crucially, they did not agree with each other.<sup class="citation"><a href="#ref-27" id="cite-27">27</a></sup> The agreement between ZeroGPT and Phrasly AI was "very good" with an intraclass correlation coefficient of 0.96, but the agreement between ZeroGPT and Grammarly was only moderate at 0.60, with substantial systematic bias between the tools.<sup class="citation"><a href="#ref-27" id="cite-27">27</a></sup> This means that whether a piece of student work is flagged as AI-generated depends significantly on which tool an educator chooses to use, rather than on any objective measure of whether the work was actually generated by AI.<sup class="citation"><a href="#ref-27" id="cite-27">27</a></sup></p>
<p>Even more troubling, this same study found that humans attempting to identify AI-generated content without the aid of detection tools performed at rates only marginally better than chance, achieving overall accuracy of just 19%, which is actually indistinguishable from randomly guessing.<sup class="citation"><a href="#ref-27" id="cite-27">27</a></sup> This finding suggests that the entire premise of detecting AI-generated content through analyzing writing patterns may be fundamentally flawed.<sup class="citation"><a href="#ref-27" id="cite-27">27</a></sup> If neither machines nor humans can reliably distinguish AI-generated text from human-written text based on style and pattern analysis alone, then the entire category of "AI detection" may represent an unsolvable problem rather than an immature technology awaiting improvement.</p>
<p>The problem of false negatives—AI-generated content that passes as human-written—deserves particular attention because it demonstrates how readily motivated students can circumvent these systems.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-11" id="cite-11">11</a>,<a href="#ref-21" id="cite-21">21</a>,<a href="#ref-26" id="cite-26">26</a></sup> One study found that when AI-generated text was edited or paraphrased using simple techniques like synonym replacement, changing sentence structure, or adding emotional language, false negative rates increased dramatically.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-21" id="cite-21">21</a>,<a href="#ref-26" id="cite-26">26</a></sup> "AI humanizers," a new category of tools specifically designed to make AI-generated text appear more human, have emerged in response to detection tools, and these humanizers are often more sophisticated than the detection tools attempting to catch them.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-26" id="cite-26">26</a></sup> In one demonstration, an expert was able to fool AI detectors 80-90% of the time simply by adding a single word—"cheeky"—to the prompt, because this word implies irreverent metaphors and unusual language patterns that break the statistical signatures detection tools look for.<sup class="citation"><a href="#ref-6" id="cite-6">6</a></sup> This ease of evasion suggests that students who are motivated to use AI without detection have readily available methods to do so, while students using AI honestly and transparently, or students who write in styles that happen to match patterns that detectors associate with AI, face false accusations.<sup class="citation"><a href="#ref-6" id="cite-6">6</a></sup></p>
<p>The Washington Post conducted an independent test of two popular AI detection tools (GPTZero and CopyLeaks) using 500 essays that were written before generative AI was even released, making them definitively human-written.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-6" id="cite-6">6</a>,<a href="#ref-7" id="cite-7">7</a></sup> In this test, the tools produced false positive rates of 1-2%, which companies cited as evidence of accuracy.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-6" id="cite-6">6</a>,<a href="#ref-7" id="cite-7">7</a></sup> However, when these percentages are applied to the scale of actual educational systems, the implications become catastrophic.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-6" id="cite-6">6</a>,<a href="#ref-7" id="cite-7">7</a></sup> If a typical first-year college student writes 10 essays per year, and there are 2.235 million first-time degree-seeking college students in the United States, that creates 22.35 million essays annually.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-6" id="cite-6">6</a>,<a href="#ref-7" id="cite-7">7</a></sup> Even with a "low" 1% false positive rate, this means that 223,500 student essays would be incorrectly flagged as AI-generated in a single year, resulting in false accusations affecting a quarter-million students.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-6" id="cite-6">6</a>,<a href="#ref-7" id="cite-7">7</a></sup> These false accusations come with severe material consequences including academic penalties, loss of scholarships, and damage to future educational and career prospects.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-6" id="cite-6">6</a>,<a href="#ref-7" id="cite-7">7</a></sup></p>
<p>A comprehensive review published by the National Center for AI noted that while models like ChatGPT enhance content creation efficiency, they raise critical ethical concerns, particularly in fields demanding precision and accuracy.<sup class="citation"><a href="#ref-3" id="cite-3">3</a>,<a href="#ref-20" id="cite-20">20</a></sup> The same review found that AI-output detectors exhibit only "moderate to high success" in distinguishing AI-generated texts, but that false positives pose significant risks to researchers and students.<sup class="citation"><a href="#ref-3" id="cite-3">3</a>,<a href="#ref-20" id="cite-20">20</a></sup> In examining studies of AI detector accuracy in academic contexts, researchers found that detection rates vary wildly depending on the specific detector, the type of content being analyzed, and how the content was generated.<sup class="citation"><a href="#ref-3" id="cite-3">3</a>,<a href="#ref-20" id="cite-20">20</a></sup> Some detectors showed accuracy rates as low as 42.9%, meaning they correctly identified the source of only about 4 in 10 submissions.<sup class="citation"><a href="#ref-3" id="cite-3">3</a>,<a href="#ref-20" id="cite-20">20</a></sup> Other detectors in the same studies achieved accuracy rates as high as 66.6%, but even this performance is inadequate for making definitive claims about academic misconduct, since it still means errors in roughly one-third of cases.<sup class="citation"><a href="#ref-3" id="cite-3">3</a>,<a href="#ref-20" id="cite-20">20</a></sup></p>
<h2>False Positives and Academic Consequences: When Innocent Work Is Flagged as AI-Generated</h2>
<p>The consequences of false positive errors—incorrectly flagging human-written work as AI-generated—extend far beyond academic penalties and represent a serious violation of student rights and institutional fairness.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-6" id="cite-6">6</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-10" id="cite-10">10</a>,<a href="#ref-11" id="cite-11">11</a>,<a href="#ref-50" id="cite-50">50</a></sup> Research demonstrates that false accusations of AI use have severe and lasting consequences for accused students, including psychological harm, financial loss, academic penalties, and in some cases, long-term damage to educational trajectories and career prospects.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-6" id="cite-6">6</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-10" id="cite-10">10</a>,<a href="#ref-11" id="cite-11">11</a>,<a href="#ref-50" id="cite-50">50</a>,<a href="#ref-56" id="cite-56">56</a>,<a href="#ref-59" id="cite-59">59</a></sup> These consequences are particularly severe because they are imposed on the basis of a flawed technological assessment, not on hard evidence of misconduct.<sup class="citation"><a href="#ref-10" id="cite-10">10</a>,<a href="#ref-50" id="cite-50">50</a></sup></p>
<p>Real-world cases illustrate the severity of these consequences. Marley Stevens, a student at the University of North Georgia, lost her scholarship after her essay was flagged as AI-generated despite being her own work, despite her not having access to AI tools, and despite using only Grammarly, the spell-checking tool that the university itself had recommended.<sup class="citation"><a href="#ref-59" id="cite-59">59</a></sup> She was placed on academic probation and subjected to a six-month misconduct and appeals process, during which she reported being unable to sleep or focus on anything, describing feeling helpless.<sup class="citation"><a href="#ref-59" id="cite-59">59</a></sup> Another case involved a student whose dissertation was flagged as 98% AI-generated despite the fact that she wrote it before ChatGPT even existed.<sup class="citation"><a href="#ref-56" id="cite-56">56</a></sup> A Texas A&M professor flunked all students in his class based on GPTZero false positives, until independent verification revealed that none of the students had actually used AI.<sup class="citation"><a href="#ref-59" id="cite-59">59</a></sup> These cases are not anomalies; they represent a growing pattern of false accusations that are fundamentally altering the educational experience for students.</p>
<p>The psychological and material impacts of false accusations extend well beyond the individual student and into broader questions about trust and institutional fairness.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-56" id="cite-56">56</a>,<a href="#ref-59" id="cite-59">59</a></sup> Students report that even going through the misconduct process for false accusations causes significant anxiety and stress, with many reporting sleep disruption, difficulty concentrating on their studies, and feelings of helplessness and violation.<sup class="citation"><a href="#ref-56" id="cite-56">56</a>,<a href="#ref-59" id="cite-59">59</a></sup> Lucie Vágnerová, an education consultant with over 10 years of experience working with students facing misconduct accusations, notes that "one of the most common feelings that students describe to me is anxiety and stress from even going through the process, even if they're saying I'm innocent. A lot of them tell me they are not sleeping well – a lot of them have to seek out counseling."<sup class="citation"><a href="#ref-56" id="cite-56">56</a></sup> The misconduct investigation process itself can take weeks or months, creating a prolonged period of uncertainty and distress that undermines students' ability to engage with their coursework.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-56" id="cite-56">56</a>,<a href="#ref-59" id="cite-59">59</a></sup> For students already facing systemic barriers and stress, false AI accusations can become the final straw leading to withdrawal from school or collapse of academic progress.</p>
<p>The material consequences of false accusations extend far beyond academic probation. Students have reported losing scholarships, being placed on academic probation that affects financial aid eligibility, having permanent marks on their academic record that damage graduate school applications, and in some cases, losing student visas and facing deportation.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-56" id="cite-56">56</a>,<a href="#ref-59" id="cite-59">59</a></sup> Accusations of academic dishonesty involving AI have, in some high-profile cases, led to students losing their visa status and becoming subjects of national news attention, demonstrating how serious these accusations are treated by institutions.<sup class="citation"><a href="#ref-56" id="cite-56">56</a></sup> Even when students are ultimately exonerated, the investigation process has already caused substantial damage to their academic standing, financial situation, and mental health. The long-term ramifications can include difficulty gaining admission to graduate programs, challenges obtaining internships or employment that requires background checks, and lasting damage to students' confidence in educational institutions.</p>
<h2>Equity Crises: Disproportionate Impact on Marginalized Students</h2>
<p>Perhaps the most damaging aspect of AI detection software is that false positives are not distributed randomly across the student population but rather disproportionately impact students who are already facing systemic barriers and discrimination within educational systems.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-8" id="cite-8">8</a>,<a href="#ref-34" id="cite-34">34</a>,<a href="#ref-38" id="cite-38">38</a>,<a href="#ref-39" id="cite-39">39</a>,<a href="#ref-42" id="cite-42">42</a></sup> Research consistently demonstrates that AI detection tools are biased against non-native English speakers, students of color, and neurodivergent students, meaning that these populations face higher rates of false accusations and are more likely to be targeted by AI detection systems.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-8" id="cite-8">8</a>,<a href="#ref-34" id="cite-34">34</a>,<a href="#ref-38" id="cite-38">38</a>,<a href="#ref-39" id="cite-39">39</a>,<a href="#ref-42" id="cite-42">42</a></sup></p>
<p>A landmark Stanford study examining seven widely-used AI detectors found that while these tools demonstrated near-perfect accuracy in evaluating essays written by U.S.-born eighth-graders, they catastrophically misclassified essays written by non-native English speakers.<sup class="citation"><a href="#ref-8" id="cite-8">8</a>,<a href="#ref-39" id="cite-39">39</a>,<a href="#ref-42" id="cite-42">42</a></sup> Specifically, the detectors classified more than half of TOEFL essays (61.22%) written by non-native English students as AI-generated, compared to nearly perfect performance on native English writing.<sup class="citation"><a href="#ref-8" id="cite-8">8</a>,<a href="#ref-39" id="cite-39">39</a>,<a href="#ref-42" id="cite-42">42</a></sup> All seven AI detectors unanimously identified 18 of 91 TOEFL student essays (19%) as AI-generated, and a remarkable 89 of the 91 TOEFL essays (97%) were flagged as AI-generated by at least one detector.<sup class="citation"><a href="#ref-8" id="cite-8">8</a>,<a href="#ref-39" id="cite-39">39</a>,<a href="#ref-42" id="cite-42">42</a></sup> This is not a minor discrepancy but rather a systematic and comprehensive failure of these tools to fairly assess non-native English writing.</p>
<p>The root cause of this bias lies in how detection tools function—they assess text based on "perplexity," a metric that correlates with the sophistication of writing.<sup class="citation"><a href="#ref-8" id="cite-8">8</a>,<a href="#ref-39" id="cite-39">39</a>,<a href="#ref-42" id="cite-42">42</a></sup> Non-native English speakers naturally score lower on perplexity measures including lexical richness, lexical diversity, syntactic complexity, and grammatical complexity, simply because they have a more limited vocabulary and grammatical range in their second language.<sup class="citation"><a href="#ref-8" id="cite-8">8</a>,<a href="#ref-39" id="cite-39">39</a>,<a href="#ref-42" id="cite-42">42</a></sup> By using perplexity as a primary detection metric, detection tools are essentially using linguistic sophistication as a proxy for human authorship, which inherently penalizes non-native speakers whose naturally limited linguistic variety gets misclassified as the "formulaic" writing patterns that AI models produce.<sup class="citation"><a href="#ref-8" id="cite-8">8</a>,<a href="#ref-39" id="cite-39">39</a>,<a href="#ref-42" id="cite-42">42</a></sup> As one Stanford researcher noted, "it comes down to how detectors detect AI. They typically score based on a metric known as 'perplexity,' which correlates with the sophistication of the writing — something in which non-native speakers are naturally going to trail their U.S.-born counterparts."<sup class="citation"><a href="#ref-8" id="cite-8">8</a>,<a href="#ref-42" id="cite-42">42</a></sup></p>
<p>Research has also documented that AI detection tools disproportionately flag writing by Black students as AI-generated, according to Common Sense Media reports cited in multiple academic sources.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-34" id="cite-34">34</a>,<a href="#ref-38" id="cite-38">38</a></sup> Neurodivergent students, including those with autism, ADHD, and dyslexia, are also more likely to be falsely flagged for AI-generated writing, partly because these students may use repeated phrases, terms, and structural patterns that detection tools associate with AI generation.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-10" id="cite-10">10</a>,<a href="#ref-11" id="cite-11">11</a>,<a href="#ref-34" id="cite-34">34</a></sup> The bias is not merely a technical problem but rather a structural problem that reflects and amplifies existing educational inequities.</p>
<p>The implications of this bias are profound and extend beyond individual students to create systemic inequity within educational institutions.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-34" id="cite-34">34</a>,<a href="#ref-38" id="cite-38">38</a></sup> Non-native English writers, students of color, and neurodivergent students are already facing systemic barriers in education—barriers related to stereotype threat, implicit bias from educators, exclusionary curriculum design, and institutional policies that do not accommodate diverse learning needs.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-34" id="cite-34">34</a>,<a href="#ref-38" id="cite-38">38</a></sup> By adding AI detection tools that disproportionately flag members of these groups as cheaters, institutions are actively exacerbating existing inequities.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-34" id="cite-34">34</a>,<a href="#ref-38" id="cite-38">38</a></sup> Furthermore, marginalized students are less likely to have the resources and social capital necessary to contest false accusations.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-34" id="cite-34">34</a>,<a href="#ref-38" id="cite-38">38</a></sup> They may lack knowledge about their rights, may face language barriers in articulating their defense, may not have access to legal representation or mentoring support, and may face implicit bias from institutional officials reviewing their cases.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-34" id="cite-34">34</a>,<a href="#ref-38" id="cite-38">38</a></sup> This creates a system in which false accusations are more likely to stick for students who can least afford the consequences.</p>
<p>The equity implications extend to considerations of who is flagged and who is protected by educational systems' choice to deploy detection tools.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-34" id="cite-34">34</a>,<a href="#ref-38" id="cite-38">38</a></sup> In a system where educator relationships and human judgment are prioritized, students benefit from teachers who know them well and can distinguish between their typical writing and atypical work. In a system where algorithmic detection is prioritized, students benefit from writing styles that happen to match the statistical patterns that algorithms have learned to associate with human writing. This essentially means that students whose writing styles are most common in the training data—typically white, native English-speaking students—are less likely to be flagged, while students whose writing styles deviate from these norms face higher risks of false accusation. By implementing AI detection systems, institutions are essentially hardcoding existing racial, linguistic, and neurological biases into their academic integrity processes.</p>
<h2>Pedagogical and Psychological Harm: Effects on Student Learning and Wellbeing</h2>
<p>Beyond the direct consequences of false accusations, the widespread adoption of AI detection tools fundamentally changes the educational environment in ways that harm student learning, undermine the development of authentic writing skills, and damage the trust relationships that are essential for effective teaching and learning.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-5" id="cite-5">5</a>,<a href="#ref-9" id="cite-9">9</a>,<a href="#ref-22" id="cite-22">22</a>,<a href="#ref-47" id="cite-47">47</a>,<a href="#ref-56" id="cite-56">56</a></sup> Research on the pedagogical implications of surveillance-based academic integrity systems reveals that detection-focused approaches create a "chilling effect" on student engagement, creative thinking, and authentic intellectual development.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-5" id="cite-5">5</a>,<a href="#ref-9" id="cite-9">9</a>,<a href="#ref-47" id="cite-47">47</a>,<a href="#ref-56" id="cite-56">56</a></sup></p>
<p>The most immediate pedagogical harm is that students report spending significant time modifying their writing to avoid detection rather than focusing on the development of their ideas.<sup class="citation"><a href="#ref-19" id="cite-19">19</a>,<a href="#ref-47" id="cite-47">47</a></sup> When students are aware that their writing will be subjected to AI detection, they begin to self-censor and modify their writing style, sometimes making it worse in the process, in an attempt to appear "more human" and avoid false accusations.<sup class="citation"><a href="#ref-19" id="cite-19">19</a>,<a href="#ref-47" id="cite-47">47</a></sup> This creates a perverse incentive structure where students are rewarded for writing that is less clear, less sophisticated, and more formulaic—precisely the opposite of what educational institutions claim to value.<sup class="citation"><a href="#ref-19" id="cite-19">19</a>,<a href="#ref-47" id="cite-47">47</a></sup> Teachers report that students are spending additional time editing their work to sound "more human," which is time that could be better spent on deeper intellectual engagement with the material.<sup class="citation"><a href="#ref-19" id="cite-19">19</a></sup> This is particularly harmful for students who are still developing their writing skills, because it diverts attention away from learning to write well and toward mimicking what they believe algorithms will classify as human writing.</p>
<p>The psychological impact of living under constant suspicion of potential cheating is also substantial and well-documented.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-47" id="cite-47">47</a>,<a href="#ref-56" id="cite-56">56</a>,<a href="#ref-59" id="cite-59">59</a></sup> Surveys of students in schools using AI detection tools reveal widespread anxiety and stress related to the possibility of false accusations.<sup class="citation"><a href="#ref-56" id="cite-56">56</a>,<a href="#ref-59" id="cite-59">59</a></sup> Students report that they feel a sense of distrust from their educators, a perception that teachers assume they are guilty unless proven innocent, and a breakdown in the relationship of mutual respect that should characterize the student-teacher dynamic.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-56" id="cite-56">56</a>,<a href="#ref-59" id="cite-59">59</a></sup> In a 2025 EDUCAUSE conference presentation, education leaders noted that students are uncertain about when AI use is allowed, often juggling conflicting policies at the course and assignment level, and this policy ambiguity compounds the anxiety created by detection tools.<sup class="citation"><a href="#ref-56" id="cite-56">56</a></sup> Some students have reported that the stress and anxiety from potential false accusations is affecting their ability to concentrate on their studies, sleep quality, and overall mental health.<sup class="citation"><a href="#ref-56" id="cite-56">56</a>,<a href="#ref-59" id="cite-59">59</a></sup></p>
<p>The broader impact of surveillance-based academic integrity systems is to foster an atmosphere of distrust between faculty and students, discourage academic participation and engagement, and undermine the perception of fairness in assessment and disciplinary processes.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-7" id="cite-7">7</a>,<a href="#ref-34" id="cite-34">34</a></sup> When students believe that their educators are using flawed technological systems to police their work rather than engaging with them as developing intellectuals, they become less likely to participate in class discussions, less likely to ask for help, and less likely to take intellectual risks that are essential for deep learning.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-5" id="cite-5">5</a>,<a href="#ref-7" id="cite-7">7</a></sup> The relationship of trust and mutual respect between teachers and students is foundational to effective learning, and by implementing detection systems that treat students as potential cheaters, institutions are undermining this essential relationship.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-5" id="cite-5">5</a>,<a href="#ref-56" id="cite-56">56</a></sup></p>
<p>A particularly troubling finding is that students report experiencing what might be called "AI anxiety"—generalized anxiety about the possibility of being falsely accused of using AI, leading them to engage in behaviors that are counterproductive to learning.<sup class="citation"><a href="#ref-56" id="cite-56">56</a></sup> Students describe feeling that they are in a "police state of writing" where they are constantly monitored and suspected.<sup class="citation"><a href="#ref-19" id="cite-19">19</a></sup> Even students who are not actually using AI report spending significant time worrying about the possibility of being falsely accused, second-guessing their own writing, and modifying their style to try to avoid triggering detection algorithms.<sup class="citation"><a href="#ref-19" id="cite-19">19</a>,<a href="#ref-56" id="cite-56">56</a></sup> This psychological burden is particularly heavy for already-marginalized students who may have experienced discrimination in educational settings and who face higher actual risk of false accusations.<sup class="citation"><a href="#ref-56" id="cite-56">56</a></sup></p>
<p>Research on how AI is affecting education more broadly reveals that while 85% of teachers and 86% of students used AI in the 2024-25 school year, these high usage rates are often accompanied by inadequate guidance about when and how to use AI appropriately.<sup class="citation"><a href="#ref-22" id="cite-22">22</a>,<a href="#ref-47" id="cite-47">47</a></sup> Seventy percent of teachers worry that AI weakens critical thinking and research skills, suggesting that educators themselves recognize that increased reliance on AI tools poses potential threats to genuine learning.<sup class="citation"><a href="#ref-22" id="cite-22">22</a>,<a href="#ref-47" id="cite-47">47</a></sup> When combined with detection-based surveillance systems, this creates an educational environment where AI is simultaneously ubiquitous, inadequately regulated, and policed through flawed technological systems—a recipe for confusion, anxiety, and reduced learning effectiveness.</p>
<h2>The Arms Race and Evasion: How Easily Motivated Students Can Defeat Detection Systems</h2>
<p>A particularly troubling aspect of the detection tool ecosystem is how easily these systems can be circumvented by motivated users, which means that the tools primarily catch students who are not trying to evade them—either because they are unaware of evasion techniques or because they are honestly trying to disclose their AI use—while allowing sophisticated cheaters to operate undetected.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-21" id="cite-21">21</a>,<a href="#ref-26" id="cite-26">26</a>,<a href="#ref-51" id="cite-51">51</a></sup> This inverts the intended function of detection tools, making them barriers to honest use while failing to catch dishonest use.</p>
<p>Multiple studies have demonstrated that simple paraphrasing techniques can reduce AI detection accuracy dramatically.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-21" id="cite-21">21</a>,<a href="#ref-51" id="cite-51">51</a></sup> One study found that running AI-generated text through a paraphrasing tool called DIPPER successfully evaded several detectors including watermarking systems, GPTZero, DetectGPT, and OpenAI's text classifier.<sup class="citation"><a href="#ref-51" id="cite-51">51</a></sup> For instance, DIPPER reduced detection accuracy of DetectGPT from 70.3% to 4.6% at a constant false positive rate of 1%, doing so without appreciably modifying the input semantics—meaning the paraphrased text still communicated the same ideas as the original AI-generated text.<sup class="citation"><a href="#ref-51" id="cite-51">51</a></sup> This demonstrates that the underlying ideas and argument structure remain the same, but the surface-level patterns that detection tools look for have been successfully obfuscated.<sup class="citation"><a href="#ref-51" id="cite-51">51</a></sup></p>
<p>Less sophisticated evasion techniques are also effective. Students can fool detectors by using simple strategies including substituting synonyms for common words, inserting emotional language and personal anecdotes, varying sentence length, adding spelling or grammatical errors, changing the tone or perspective, and writing as if they were a non-native English speaker.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-26" id="cite-26">26</a></sup> One expert demonstrated that adding a single word—"cheeky"—to a prompt could fool detectors 80-90% of the time because this word implies irreverent and unusual language patterns that break statistical signatures.<sup class="citation"><a href="#ref-6" id="cite-6">6</a></sup> Prompt engineering—the practice of carefully crafting instructions given to language models to produce specific outputs—can also be used to make AI-generated text more human-like and harder to detect.<sup class="citation"><a href="#ref-8" id="cite-8">8</a></sup> A student could simply ask ChatGPT to "elevate the provided text by employing literary language" and the resulting text would be harder for detectors to identify as AI-generated, even though the underlying ideas remain AI-generated.<sup class="citation"><a href="#ref-8" id="cite-8">8</a></sup></p>
<p>A category of tools called "AI humanizers" has emerged specifically to make AI-generated text undetectable.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-26" id="cite-26">26</a></sup> These tools use algorithms to change text features that detectors typically catch, focusing on disrupting perplexity manipulation, enhancing burstiness, and disrupting statistical patterns that detectors look for.<sup class="citation"><a href="#ref-26" id="cite-26">26</a></sup> The existence of these tools demonstrates that there is a substantial market for evasion techniques, suggesting that many students are aware that detection tools are flawed and are seeking ways to circumvent them. This creates a dynamic where sophisticated students—who typically come from privileged backgrounds with greater access to information about evasion techniques—can use AI without detection, while less-sophisticated students or marginalized students who are trying to use AI honestly may be more likely to be flagged.</p>
<p>The "arms race" between detection tools and generation tools means that this problem will only get worse over time.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-21" id="cite-21">21</a></sup> As language models become more sophisticated and capable of producing text that is increasingly indistinguishable from human writing, the task of detection becomes progressively more difficult.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-21" id="cite-21">21</a></sup> Meanwhile, developers of evasion tools will continue to innovate, creating new techniques for defeating detection systems.<sup class="citation"><a href="#ref-6" id="cite-6">6</a>,<a href="#ref-21" id="cite-21">21</a></sup> This dynamic was described by one researcher as "an ongoing technological arms race," comparable to the never-ending competition between cybercriminals and security researchers, and suggests that "there's no silver bullet to solve the problems AI-generated text poses. Quite likely, there won't ever be."<sup class="citation"><a href="#ref-6" id="cite-6">6</a></sup></p>
<h2>Institutional Responses and Policy Shifts: Moving Away From Detection</h2>
<p>In response to growing evidence of the inadequacy and harmfulness of AI detection tools, numerous institutions have begun disabling these features, revisiting their policies, and shifting toward alternative approaches to academic integrity in an AI-augmented world.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup> This institutional shift is significant because it represents a recognition that detection tools, while intuitively appealing as a technological solution to an educational problem, do not actually solve that problem and instead create new problems.</p>
<p>The University of Waterloo announced in 2025 that it would discontinue Turnitin's AI detection feature entirely.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup> UMass Amherst deactivated Turnitin's AI detection feature based on guidance from its teaching center that identified "significant limitations" in AI detection tools.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup> Australian Catholic University paused Turnitin's AI indicator after false accusations led to lengthy investigations, and other Australian institutions have signaled similar moves.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup> These institutional decisions did not come from skepticism about the existence of AI-generated content in student work, but rather from recognition that the tools designed to catch such content are sufficiently unreliable that they should not be used as a basis for high-stakes academic misconduct decisions.</p>
<p>Australian regulators have been particularly explicit in their judgment of AI detection tools. TEQSA (Tertiary Education Quality and Standards Agency), the regulatory body for Australian higher education, stated clearly that "detecting gen AI use with certainty in assessments is, at this point, all but impossible," and urged educational providers to build in at least one secure assessment per unit and to redesign tasks rather than to rely on detection tools.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup> This regulatory statement represents an explicit acknowledgment that the problem cannot be solved through technical detection means.</p>
<p>The consensus among institutions moving away from detection appears to be that the appropriate response to widespread AI use is not to attempt to detect and punish it, but rather to redesign assessments and build process evidence into academic evaluation.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup> This represents a fundamental shift in how institutions are thinking about academic integrity in an AI-augmented world—moving away from a "catch and punish" model and toward a "design for authenticity" model.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup> The logic of this approach is straightforward: rather than attempting to determine whether a finished product was created with or without AI (a fundamentally impossible task given the limitations of detection tools), institutions should design assignments and assessments in ways that either require genuine student engagement with the material or that make it possible to evaluate the student's thinking process alongside the finished product.</p>
<p>A major shift visible in 2025 is increased emphasis on process evidence, draft history, version tracking, and documentation of the student's thinking and development over time.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup> Learning management systems are increasingly incorporating features that allow educators to see the drafting process, track changes, review notes and outlines, and observe how a student's thinking evolves over the course of an assignment.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup> This process-focused approach provides much more reliable evidence of student learning and authorship than any detector could provide, because it makes it difficult for a student to claim authorship of work they did not actually develop.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup> A student who relies entirely on AI and merely pastes the output into their submission will have no evidence of process, no drafts showing progression, and no notes or thinking about how they developed their ideas. By contrast, a student who genuinely engages with an assignment will have evidence of their thinking, their revisions, their struggles with concepts, and the intellectual work they undertook.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup></p>
<p>University of Minnesota provides a clear institutional statement: "Given these limitations, the University of Minnesota does not centrally support or recommend the use of any GenAI detection tool."<sup class="citation"><a href="#ref-10" id="cite-10">10</a></sup> Instead, the university recommends that institutions foster a culture of ethical use, include clear statements about AI use in syllabi, discuss AI and academic integrity with students, teach students how to acknowledge their use of AI appropriately, use grading schemas that reward originality and analysis, and promote meaningful assessments that inherently resist AI use or that require students to do original thinking that no AI system could complete.<sup class="citation"><a href="#ref-10" id="cite-10">10</a></sup> This guidance aligns with recommendations from leading educational institutions including MIT Sloan EdTech, which advises that detectors should only be treated as a "triage role," as a signal to investigate further rather than as evidence of misconduct.<sup class="citation"><a href="#ref-48" id="cite-48">48</a></sup></p>
<h2>Alternative Approaches: Assessment Redesign and Process-Focused Evaluation</h2>
<p>As institutions move away from detection-based approaches, they are simultaneously moving toward pedagogically sound alternatives that address the underlying problem more effectively.<sup class="citation"><a href="#ref-2" id="cite-2">2</a>,<a href="#ref-5" id="cite-5">5</a>,<a href="#ref-43" id="cite-43">43</a>,<a href="#ref-44" id="cite-44">44</a></sup></p>
    </article>
    
    <section class="references" id="references">
        <h2>References</h2>
        <ol>
            <li id="ref-1">
        <a href="#cite-1" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">1.</span>
        "iacis.org." Accessed February 5, 2026.
        <a href="https://iacis.org/iis/2025/3_iis_2025_401-412.pdf" target="_blank" rel="noopener">https://iacis.org/iis/2025/3_iis_2025_401-412.pdf</a>
    </li>
<li id="ref-2">
        <a href="#cite-2" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">2.</span>
        "citl.news.niu.edu." Accessed February 5, 2026.
        <a href="https://citl.news.niu.edu/2024/12/12/ai-detectors-an-ethical-minefield/" target="_blank" rel="noopener">https://citl.news.niu.edu/2024/12/12/ai-detectors-an-ethical-minefield/</a>
    </li>
<li id="ref-3">
        <a href="#cite-3" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">3.</span>
        "pmc.ncbi.nlm.nih.gov." Accessed February 5, 2026.
        <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12331776/" target="_blank" rel="noopener">https://pmc.ncbi.nlm.nih.gov/articles/PMC12331776/</a>
    </li>
<li id="ref-4">
        <a href="#cite-4" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">4.</span>
        "nationalcentreforai.jiscinvolve.org." Accessed February 5, 2026.
        <a href="https://nationalcentreforai.jiscinvolve.org/wp/2025/06/24/ai-detection-assessment-2025/" target="_blank" rel="noopener">https://nationalcentreforai.jiscinvolve.org/wp/2025/06/24/ai-detection-assessment-2025/</a>
    </li>
<li id="ref-5">
        <a href="#cite-5" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">5.</span>
        "teach.its.uiowa.edu." Accessed February 5, 2026.
        <a href="https://teach.its.uiowa.edu/news/2024/09/case-against-ai-detectors" target="_blank" rel="noopener">https://teach.its.uiowa.edu/news/2024/09/case-against-ai-detectors</a>
    </li>
<li id="ref-6">
        <a href="#cite-6" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">6.</span>
        "lawlibguides.sandiego.edu." Accessed February 5, 2026.
        <a href="https://lawlibguides.sandiego.edu/c.php?g=1443311&p=10721367" target="_blank" rel="noopener">https://lawlibguides.sandiego.edu/c.php?g=1443311&p=10721367</a>
    </li>
<li id="ref-7">
        <a href="#cite-7" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">7.</span>
        "citl.news.niu.edu." Accessed February 5, 2026.
        <a href="https://citl.news.niu.edu/2024/12/12/ai-detectors-an-ethical-minefield/" target="_blank" rel="noopener">https://citl.news.niu.edu/2024/12/12/ai-detectors-an-ethical-minefield/</a>
    </li>
<li id="ref-8">
        <a href="#cite-8" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">8.</span>
        "hai.stanford.edu." Accessed February 5, 2026.
        <a href="https://hai.stanford.edu/news/ai-detectors-biased-against-non-native-english-writers" target="_blank" rel="noopener">https://hai.stanford.edu/news/ai-detectors-biased-against-non-native-english-writers</a>
    </li>
<li id="ref-9">
        <a href="#cite-9" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">9.</span>
        "teach.its.uiowa.edu." Accessed February 5, 2026.
        <a href="https://teach.its.uiowa.edu/news/2024/09/case-against-ai-detectors" target="_blank" rel="noopener">https://teach.its.uiowa.edu/news/2024/09/case-against-ai-detectors</a>
    </li>
<li id="ref-10">
        <a href="#cite-10" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">10.</span>
        "teachingsupport.umn.edu." Accessed February 5, 2026.
        <a href="https://teachingsupport.umn.edu/what-faculty-should-know-about-genai-detectors" target="_blank" rel="noopener">https://teachingsupport.umn.edu/what-faculty-should-know-about-genai-detectors</a>
    </li>
<li id="ref-11">
        <a href="#cite-11" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">11.</span>
        "lawlibguides.sandiego.edu." Accessed February 5, 2026.
        <a href="https://lawlibguides.sandiego.edu/c.php?g=1443311&p=10721367" target="_blank" rel="noopener">https://lawlibguides.sandiego.edu/c.php?g=1443311&p=10721367</a>
    </li>
<li id="ref-12">
        <a href="#cite-12" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">12.</span>
        "onlinelearningconsortium.org." Accessed February 5, 2026.
        <a href="https://onlinelearningconsortium.org/olc-insights/2026/01/ethical-ai/" target="_blank" rel="noopener">https://onlinelearningconsortium.org/olc-insights/2026/01/ethical-ai/</a>
    </li>
<li id="ref-13">
        <a href="#cite-13" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">13.</span>
        "litero.ai." Accessed February 5, 2026.
        <a href="https://litero.ai/blog/how-ai-detectors-actually-work-the-truth-about-undetectable-ai-tools-2025-guide/" target="_blank" rel="noopener">https://litero.ai/blog/how-ai-detectors-actually-work-the-truth-about-undetectable-ai-tools-2025-guide/</a>
    </li>
<li id="ref-14">
        <a href="#cite-14" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">14.</span>
        "ampifire.com." Accessed February 5, 2026.
        <a href="https://ampifire.com/blog/gptzero-vs-turnitin-which-is-the-better-ai-detector/" target="_blank" rel="noopener">https://ampifire.com/blog/gptzero-vs-turnitin-which-is-the-better-ai-detector/</a>
    </li>
<li id="ref-15">
        <a href="#cite-15" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">15.</span>
        "hastewire.com." Accessed February 5, 2026.
        <a href="https://hastewire.com/blog/how-ai-detectors-work-technical-breakdown-explained" target="_blank" rel="noopener">https://hastewire.com/blog/how-ai-detectors-work-technical-breakdown-explained</a>
    </li>
<li id="ref-16">
        <a href="#cite-16" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">16.</span>
        "nationalcentreforai.jiscinvolve.org." Accessed February 5, 2026.
        <a href="https://nationalcentreforai.jiscinvolve.org/wp/2025/06/24/ai-detection-assessment-2025/" target="_blank" rel="noopener">https://nationalcentreforai.jiscinvolve.org/wp/2025/06/24/ai-detection-assessment-2025/</a>
    </li>
<li id="ref-17">
        <a href="#cite-17" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">17.</span>
        "hastewire.com." Accessed February 5, 2026.
        <a href="https://hastewire.com/blog/copyleaks-vs-turnitin-which-wins-for-ai-detection-in-2025" target="_blank" rel="noopener">https://hastewire.com/blog/copyleaks-vs-turnitin-which-wins-for-ai-detection-in-2025</a>
    </li>
<li id="ref-18">
        <a href="#cite-18" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">18.</span>
        "gptzero.me." Accessed February 5, 2026.
        <a href="https://gptzero.me/news/perplexity-and-burstiness-what-is-it/" target="_blank" rel="noopener">https://gptzero.me/news/perplexity-and-burstiness-what-is-it/</a>
    </li>
<li id="ref-19">
        <a href="#cite-19" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">19.</span>
        "cengagegroup.com." Accessed February 5, 2026.
        <a href="https://www.cengagegroup.com/news/perspectives/2025/ais-impact-on-education-in-2025/" target="_blank" rel="noopener">https://www.cengagegroup.com/news/perspectives/2025/ais-impact-on-education-in-2025/</a>
    </li>
<li id="ref-20">
        <a href="#cite-20" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">20.</span>
        "pmc.ncbi.nlm.nih.gov." Accessed February 5, 2026.
        <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12331776/" target="_blank" rel="noopener">https://pmc.ncbi.nlm.nih.gov/articles/PMC12331776/</a>
    </li>
<li id="ref-21">
        <a href="#cite-21" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">21.</span>
        "prodev.illinoisstate.edu." Accessed February 5, 2026.
        <a href="https://prodev.illinoisstate.edu/instructional-resources/pedagogy/ai/detectors/" target="_blank" rel="noopener">https://prodev.illinoisstate.edu/instructional-resources/pedagogy/ai/detectors/</a>
    </li>
<li id="ref-22">
        <a href="#cite-22" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">22.</span>
        "online.ysu.edu." Accessed February 5, 2026.
        <a href="https://online.ysu.edu/degrees/education/msed/ai-teaching-statistics-usage-and-trends/" target="_blank" rel="noopener">https://online.ysu.edu/degrees/education/msed/ai-teaching-statistics-usage-and-trends/</a>
    </li>
<li id="ref-23">
        <a href="#cite-23" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">23.</span>
        "teaching.pitt.edu." Accessed February 5, 2026.
        <a href="https://teaching.pitt.edu/resources/encouraging-academic-integrity/" target="_blank" rel="noopener">https://teaching.pitt.edu/resources/encouraging-academic-integrity/</a>
    </li>
<li id="ref-24">
        <a href="#cite-24" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">24.</span>
        "libraryhelp.sfcc.edu." Accessed February 5, 2026.
        <a href="https://libraryhelp.sfcc.edu/generative-AI/detectors" target="_blank" rel="noopener">https://libraryhelp.sfcc.edu/generative-AI/detectors</a>
    </li>
<li id="ref-25">
        <a href="#cite-25" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">25.</span>
        "aclanthology.org." Accessed February 5, 2026.
        <a href="https://aclanthology.org/2025.genaidetect-1.9.pdf" target="_blank" rel="noopener">https://aclanthology.org/2025.genaidetect-1.9.pdf</a>
    </li>
<li id="ref-26">
        <a href="#cite-26" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">26.</span>
        "learnprompting.org." Accessed February 5, 2026.
        <a href="https://learnprompting.org/docs/miscl/trickery" target="_blank" rel="noopener">https://learnprompting.org/docs/miscl/trickery</a>
    </li>
<li id="ref-27">
        <a href="#cite-27" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">27.</span>
        "pmc.ncbi.nlm.nih.gov." Accessed February 5, 2026.
        <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12752165/" target="_blank" rel="noopener">https://pmc.ncbi.nlm.nih.gov/articles/PMC12752165/</a>
    </li>
<li id="ref-28">
        <a href="#cite-28" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">28.</span>
        "hastewire.com." Accessed February 5, 2026.
        <a href="https://hastewire.com/blog/ai-detection-benchmark-2025-top-accuracy-results" target="_blank" rel="noopener">https://hastewire.com/blog/ai-detection-benchmark-2025-top-accuracy-results</a>
    </li>
<li id="ref-29">
        <a href="#cite-29" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">29.</span>
        "research.checkpoint.com." Accessed February 5, 2026.
        <a href="https://research.checkpoint.com/2025/ai-evasion-prompt-injection/" target="_blank" rel="noopener">https://research.checkpoint.com/2025/ai-evasion-prompt-injection/</a>
    </li>
<li id="ref-30">
        <a href="#cite-30" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">30.</span>
        "gowinston.ai." Accessed February 5, 2026.
        <a href="https://gowinston.ai/why-do-ai-detectors-give-different-results/" target="_blank" rel="noopener">https://gowinston.ai/why-do-ai-detectors-give-different-results/</a>
    </li>
<li id="ref-31">
        <a href="#cite-31" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">31.</span>
        "nea.org." Accessed February 5, 2026.
        <a href="https://www.nea.org/sites/default/files/2025-06/5.1-ai-policy-overview-of-federal-regulations-final.pdf" target="_blank" rel="noopener">https://www.nea.org/sites/default/files/2025-06/5.1-ai-policy-overview-of-federal-regulations-final.pdf</a>
    </li>
<li id="ref-32">
        <a href="#cite-32" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">32.</span>
        "asccc.org." Accessed February 5, 2026.
        <a href="https://www.asccc.org/content/rights-and-responsibilities-regarding-ai-use-academia" target="_blank" rel="noopener">https://www.asccc.org/content/rights-and-responsibilities-regarding-ai-use-academia</a>
    </li>
<li id="ref-33">
        <a href="#cite-33" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">33.</span>
        "brookings.edu." Accessed February 5, 2026.
        <a href="https://www.brookings.edu/articles/detecting-ai-fingerprints-a-guide-to-watermarking-and-beyond/" target="_blank" rel="noopener">https://www.brookings.edu/articles/detecting-ai-fingerprints-a-guide-to-watermarking-and-beyond/</a>
    </li>
<li id="ref-34">
        <a href="#cite-34" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">34.</span>
        "citl.news.niu.edu." Accessed February 5, 2026.
        <a href="https://citl.news.niu.edu/2024/12/12/ai-detectors-an-ethical-minefield/" target="_blank" rel="noopener">https://citl.news.niu.edu/2024/12/12/ai-detectors-an-ethical-minefield/</a>
    </li>
<li id="ref-35">
        <a href="#cite-35" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">35.</span>
        "onlinelearningconsortium.org." Accessed February 5, 2026.
        <a href="https://onlinelearningconsortium.org/olc-insights/2026/01/ethical-ai/" target="_blank" rel="noopener">https://onlinelearningconsortium.org/olc-insights/2026/01/ethical-ai/</a>
    </li>
<li id="ref-36">
        <a href="#cite-36" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">36.</span>
        "digitalbricks.ai." Accessed February 5, 2026.
        <a href="https://www.digitalbricks.ai/blog-posts/generative-ai-watermarking" target="_blank" rel="noopener">https://www.digitalbricks.ai/blog-posts/generative-ai-watermarking</a>
    </li>
<li id="ref-37">
        <a href="#cite-37" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">37.</span>
        "gptzero.me." Accessed February 5, 2026.
        <a href="https://gptzero.me/news/best-ai-detectors/" target="_blank" rel="noopener">https://gptzero.me/news/best-ai-detectors/</a>
    </li>
<li id="ref-38">
        <a href="#cite-38" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">38.</span>
        "citl.news.niu.edu." Accessed February 5, 2026.
        <a href="https://citl.news.niu.edu/2024/12/12/ai-detectors-an-ethical-minefield/" target="_blank" rel="noopener">https://citl.news.niu.edu/2024/12/12/ai-detectors-an-ethical-minefield/</a>
    </li>
<li id="ref-39">
        <a href="#cite-39" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">39.</span>
        "pmc.ncbi.nlm.nih.gov." Accessed February 5, 2026.
        <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC10382961/" target="_blank" rel="noopener">https://pmc.ncbi.nlm.nih.gov/articles/PMC10382961/</a>
    </li>
<li id="ref-40">
        <a href="#cite-40" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">40.</span>
        "youtube.com." Accessed February 5, 2026.
        <a href="https://www.youtube.com/watch?v=N3RtTCF9E8g" target="_blank" rel="noopener">https://www.youtube.com/watch?v=N3RtTCF9E8g</a>
    </li>
<li id="ref-41">
        <a href="#cite-41" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">41.</span>
        "pmc.ncbi.nlm.nih.gov." Accessed February 5, 2026.
        <a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC12057767/" target="_blank" rel="noopener">https://pmc.ncbi.nlm.nih.gov/articles/PMC12057767/</a>
    </li>
<li id="ref-42">
        <a href="#cite-42" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">42.</span>
        "hai.stanford.edu." Accessed February 5, 2026.
        <a href="https://hai.stanford.edu/news/ai-detectors-biased-against-non-native-english-writers" target="_blank" rel="noopener">https://hai.stanford.edu/news/ai-detectors-biased-against-non-native-english-writers</a>
    </li>
<li id="ref-43">
        <a href="#cite-43" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">43.</span>
        "teaching.resources.osu.edu." Accessed February 5, 2026.
        <a href="https://teaching.resources.osu.edu/teaching-topics/ai-teaching-strategies-transparent" target="_blank" rel="noopener">https://teaching.resources.osu.edu/teaching-topics/ai-teaching-strategies-transparent</a>
    </li>
<li id="ref-44">
        <a href="#cite-44" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">44.</span>
        "ed.gov." Accessed February 5, 2026.
        <a href="http://www.ed.gov/about/news/press-release/us-department-of-education-issues-guidance-artificial-intelligence-use-schools-proposes-additional-supplemental-priority" target="_blank" rel="noopener">http://www.ed.gov/about/news/press-release/us-department-of-education-issues-guidance-artificial-intelligence-use-schools-proposes-additional-supplemental-priority</a>
    </li>
<li id="ref-45">
        <a href="#cite-45" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">45.</span>
        "turnitin.app." Accessed February 5, 2026.
        <a href="https://turnitin.app/blog/The-Truth-About-Turnitins-AI-Detection-Accuracy-in-2025.html" target="_blank" rel="noopener">https://turnitin.app/blog/The-Truth-About-Turnitins-AI-Detection-Accuracy-in-2025.html</a>
    </li>
<li id="ref-46">
        <a href="#cite-46" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">46.</span>
        "ctl.stanford.edu." Accessed February 5, 2026.
        <a href="https://ctl.stanford.edu/strategies-assigning-ai-use" target="_blank" rel="noopener">https://ctl.stanford.edu/strategies-assigning-ai-use</a>
    </li>
<li id="ref-47">
        <a href="#cite-47" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">47.</span>
        "edweek.org." Accessed February 5, 2026.
        <a href="https://www.edweek.org/technology/rising-use-of-ai-in-schools-comes-with-big-downsides-for-students/2025/10" target="_blank" rel="noopener">https://www.edweek.org/technology/rising-use-of-ai-in-schools-comes-with-big-downsides-for-students/2025/10</a>
    </li>
<li id="ref-48">
        <a href="#cite-48" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">48.</span>
        "markcarrigan.net." Accessed February 5, 2026.
        <a href="https://markcarrigan.net/2025/10/13/has-there-been-any-improvement-in-ai-detectors-over-the-last-12-months-a-gpt-5-pro-literature-review/" target="_blank" rel="noopener">https://markcarrigan.net/2025/10/13/has-there-been-any-improvement-in-ai-detectors-over-the-last-12-months-a-gpt-5-pro-literature-review/</a>
    </li>
<li id="ref-49">
        <a href="#cite-49" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">49.</span>
        "iacis.org." Accessed February 5, 2026.
        <a href="https://iacis.org/iis/2025/3_iis_2025_401-412.pdf" target="_blank" rel="noopener">https://iacis.org/iis/2025/3_iis_2025_401-412.pdf</a>
    </li>
<li id="ref-50">
        <a href="#cite-50" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">50.</span>
        "blogs.ncl.ac.uk." Accessed February 5, 2026.
        <a href="https://blogs.ncl.ac.uk/sin/2025/08/05/the-unfairness-of-ai-flagged-academic-misconduct-investigations-in-uk-universities/" target="_blank" rel="noopener">https://blogs.ncl.ac.uk/sin/2025/08/05/the-unfairness-of-ai-flagged-academic-misconduct-investigations-in-uk-universities/</a>
    </li>
<li id="ref-51">
        <a href="#cite-51" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">51.</span>
        "openreview.net." Accessed February 5, 2026.
        <a href="https://openreview.net/forum?id=WbFhFvjjKj" target="_blank" rel="noopener">https://openreview.net/forum?id=WbFhFvjjKj</a>
    </li>
<li id="ref-52">
        <a href="#cite-52" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">52.</span>
        "nationalcentreforai.jiscinvolve.org." Accessed February 5, 2026.
        <a href="https://nationalcentreforai.jiscinvolve.org/wp/2025/06/24/ai-detection-assessment-2025/" target="_blank" rel="noopener">https://nationalcentreforai.jiscinvolve.org/wp/2025/06/24/ai-detection-assessment-2025/</a>
    </li>
<li id="ref-53">
        <a href="#cite-53" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">53.</span>
        "unk.edu." Accessed February 5, 2026.
        <a href="https://www.unk.edu/academics/academic-innovation/ai-lab/evaluating-ai-detection-tools-guidance-for-instructors.php" target="_blank" rel="noopener">https://www.unk.edu/academics/academic-innovation/ai-lab/evaluating-ai-detection-tools-guidance-for-instructors.php</a>
    </li>
<li id="ref-54">
        <a href="#cite-54" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">54.</span>
        "arxiv.org." Accessed February 5, 2026.
        <a href="https://arxiv.org/html/2401.05952v2" target="_blank" rel="noopener">https://arxiv.org/html/2401.05952v2</a>
    </li>
<li id="ref-55">
        <a href="#cite-55" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">55.</span>
        "learningtree.com." Accessed February 5, 2026.
        <a href="https://www.learningtree.com/blog/carbon-footprint-ai-deep-learning/" target="_blank" rel="noopener">https://www.learningtree.com/blog/carbon-footprint-ai-deep-learning/</a>
    </li>
<li id="ref-56">
        <a href="#cite-56" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">56.</span>
        "govtech.com." Accessed February 5, 2026.
        <a href="https://www.govtech.com/education/higher-ed/educause-25-how-ai-policies-affect-student-mental-health" target="_blank" rel="noopener">https://www.govtech.com/education/higher-ed/educause-25-how-ai-policies-affect-student-mental-health</a>
    </li>
<li id="ref-57">
        <a href="#cite-57" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">57.</span>
        "quinnemanuel.com." Accessed February 5, 2026.
        <a href="https://www.quinnemanuel.com/the-firm/publications/when-machines-discriminate-the-rise-of-ai-bias-lawsuits/" target="_blank" rel="noopener">https://www.quinnemanuel.com/the-firm/publications/when-machines-discriminate-the-rise-of-ai-bias-lawsuits/</a>
    </li>
<li id="ref-58">
        <a href="#cite-58" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">58.</span>
        "climateimpact.com." Accessed February 5, 2026.
        <a href="https://www.climateimpact.com/news-insights/insights/carbon-footprint-of-ai/" target="_blank" rel="noopener">https://www.climateimpact.com/news-insights/insights/carbon-footprint-of-ai/</a>
    </li>
<li id="ref-59">
        <a href="#cite-59" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">59.</span>
        "the-independent.com." Accessed February 5, 2026.
        <a href="https://www.the-independent.com/news/world/americas/ai-detection-cheating-schools-b2894837.html" target="_blank" rel="noopener">https://www.the-independent.com/news/world/americas/ai-detection-cheating-schools-b2894837.html</a>
    </li>
<li id="ref-60">
        <a href="#cite-60" class="back-ref" title="Back to text">↩</a>
        <span class="cite-num">60.</span>
        "kaltmanlaw.com." Accessed February 5, 2026.
        <a href="https://www.kaltmanlaw.com/post/can-you-get-kicked-out-of-college-for-using-ai" target="_blank" rel="noopener">https://www.kaltmanlaw.com/post/can-you-get-kicked-out-of-college-for-using-ai</a>
    </li>
        </ol>
    </section>
    <footer>filed under: things worth knowing</footer>
</body>
</html>