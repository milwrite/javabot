<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Classic creative coding visualizations made by computers in the 1970s, 80s, 9...</title>
    <style>
        * { box-sizing: border-box; margin: 0; padding: 0; }
        body {
            font-family: 'Courier New', monospace;
            background: #0a0a0a;
            color: #7ec8e3;
            line-height: 1.6;
            padding: 40px 20px 60px;
            max-width: 720px;
            margin: 0 auto;
        }
        a { color: #00ffff; text-decoration: none; }
        a:hover { color: #ff0000; text-decoration: underline; }
        .home-link { display: inline-block; margin-bottom: 30px; font-size: 13px; }
        .home-link::before { content: '← '; }
        header { margin-bottom: 40px; padding-bottom: 20px; border-bottom: 1px solid #333; }
        header h1 { color: #ff0000; font-size: 20px; font-weight: normal; margin-bottom: 8px; }
        header .meta { font-size: 12px; color: #555; }
        article { color: #7ec8e3; }
        article h1 { color: #00ffff; font-size: 17px; font-weight: normal; margin: 35px 0 15px; }
        article h2 { color: #ff0000; font-size: 15px; font-weight: normal; margin: 30px 0 12px; }
        article h3 { color: #7ec8e3; font-size: 14px; font-weight: normal; margin: 20px 0 10px; }
        article p { margin-bottom: 16px; }
        article ul, article ol { margin-left: 20px; margin-bottom: 16px; }
        article li { margin-bottom: 8px; }
        article strong { color: #00ffff; font-weight: normal; }
        article em { font-style: normal; color: #888; }

        /* Citation styling */
        .citation { font-size: 0.75em; vertical-align: super; line-height: 0; }
        .citation a { color: #ff0000; padding: 0 1px; }
        .citation a:hover { color: #ff9999; text-decoration: underline; }

        /* Citations/References section */
        .citations {
            margin-top: 50px;
            padding-top: 25px;
            border-top: 1px solid #333;
        }
        .citations h2 {
            color: #ff0000;
            font-size: 14px;
            margin-bottom: 20px;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        .citations ol {
            list-style: none;
            padding: 0;
        }
        .citations li {
            font-size: 12px;
            margin: 12px 0;
            padding-left: 30px;
            position: relative;
            line-height: 1.5;
            word-break: break-word;
            color: #666;
        }
        .citations .back-ref {
            position: absolute;
            left: 0;
            top: 0;
            color: #ff0000;
            text-decoration: none;
            font-size: 11px;
        }
        .citations .back-ref:hover { color: #ff9999; }
        .citations .cite-num {
            color: #666;
            margin-right: 8px;
        }
        .citations li a:not(.back-ref) {
            color: #00ffff;
            word-break: break-all;
        }
        .citations li a:not(.back-ref):hover { color: #ff0000; }

        footer { margin-top: 60px; padding-top: 20px; border-top: 1px solid #222; font-size: 11px; color: #444; }
        @media (max-width: 600px) {
            body { padding: 25px 15px 40px; }
            header h1 { font-size: 18px; }
        }
    </style>
</head>
<body>
    <a class="home-link" href="../../index.html"></a>
    <header>
        <h1>Classic creative coding visualizations made by computers in the 1970s, 80s, 9...</h1>
        <div class="meta">researched Feb 21, 2026 · dug up by sportello</div>
    </header>
    <article>
        <h1>Creative Coding Visualizations: A Comprehensive Historical Survey of Computational Art from the 1950s to the 2020s</h1>
<p>This comprehensive report traces the evolution of creative coding visualizations across seven decades, examining the pioneering works, fundamental techniques, and cultural shifts that have defined computational art from its earliest manifestations in the 1950s through the contemporary digital landscape of the 2020s. The research identifies major visualization categories including algorithmic drawing, generative systems, mathematical transformations, real-time rendering, and blockchain-based generative art, while analyzing the technological constraints and innovations that shaped each era's distinctive aesthetic. By examining seminal projects such as Georg Nees's Schotter, John Conway's Game of Life, the demoscene movement, Processing-based works, and contemporary NFT generative art, this report establishes a chronological and categorical framework that illuminates how artists and programmers have consistently pushed computational systems toward expressive ends rather than purely functional ones.</p>
<h2>The Dawn of Computational Aesthetics: The 1950s and Early 1960s</h2>
<h3>Oscilloscopic Abstractions and the First Electronic Art</h3>
<p>The history of creative coding visualizations begins not with computers in the modern sense, but with electronic instruments repurposed toward aesthetic ends.<sup class="citation"><a href="#ref-7" id="cite-7">7</a></sup> Ben Laposky, an American draftsman and mathematician, created what are widely considered the earliest computer graphics in 1950 using a cathode ray oscilloscope equipped with sine wave generators and various electronic circuits.<sup class="citation"><a href="#ref-7" id="cite-7">7</a>,<a href="#ref-10" id="cite-10">10</a></sup> Working in Cherokee, Iowa, Laposky called these works "electrical compositions," capturing the moving outputs using long-exposure photography to record the abstract patterns produced by oscilloscopes.<sup class="citation"><a href="#ref-10" id="cite-10">10</a></sup> His approach fundamentally demonstrated that sophisticated visual patterns could emerge from relatively simple mathematical functions, establishing a principle that would become central to creative coding practice throughout subsequent decades. In 1952, some of Laposky's images were published in Scripta Mathematica, and these works have been credited as the earliest computer graphics.<sup class="citation"><a href="#ref-7" id="cite-7">7</a></sup> By 1953, Laposky exhibited fifty images he called "Oscillons" at the Sanford Museum in his hometown, garnering an exhibition catalog that documented his artistic philosophy and establishing him as the earliest pioneer in electronic art, specifically in the analog vector medium.<sup class="citation"><a href="#ref-7" id="cite-7">7</a></sup> The significance of Laposky's work lay not merely in its technical novelty but in its philosophical assertion that computational systems could generate expressive rather than merely utilitarian output, challenging fundamental assumptions about the relationship between mathematical precision and aesthetic beauty.</p>
<h3>The Birth of Digital Computer Art: 1960-1965</h3>
<p>The transition from analog oscilloscopic art to digital computer-generated imagery occurred rapidly in the early 1960s, driven by the increasing availability of computers in academic and research institutions.<sup class="citation"><a href="#ref-4" id="cite-4">4</a>,<a href="#ref-10" id="cite-10">10</a></sup> Between 1963 and 1965, a cohort of mathematicians, physicists, and engineers began experimenting with the computational generation of visual form, fundamentally reshaping the relationship between art and technology. Frieder Nake, a German mathematician and computer scientist, produced his earliest computer artworks in 1963, influenced by the philosopher Max Bense's theoretical framework regarding aesthetic systems. Working with early computing systems and specialized drawing equipment, Nake became one of the first practitioners to use algorithms as an artistic medium rather than merely a technical tool. In November 1965, Nake exhibited his computer-generated works at the Galerie Wendelin Niedlich in Stuttgart in an exhibition titled "Computer-Grafik," representing one of the first exhibitions of computer art with explicit aesthetic intention. The same year witnessed the parallel work of Georg Nees, born in Nuremberg in 1926, who worked as a software engineer for Siemens and was instrumental in their acquisition of a Zuse Graphomat drawing machine operated through computer-generated punched tape.<sup class="citation"><a href="#ref-3" id="cite-3">3</a>,<a href="#ref-6" id="cite-6">6</a></sup> Nees's work, particularly his creation of Schotter between 1968 and 1970, explored the mathematical relationship between order and disorder in pictorial composition by introducing random variables into computer programs that would generate geometric patterns.<sup class="citation"><a href="#ref-3" id="cite-3">3</a></sup> The work was subsequently lithographed and is now held in the Victoria and Albert Museum's collection, cementing its historical significance as a foundational work in generative art. Ken Knowlton, working at Bell Labs, contributed significantly to early computer art through the invention of BEFLIX, a programming language capable of outputting raster animated films in 1963.<sup class="citation"><a href="#ref-10" id="cite-10">10</a></sup> The term "pixel" was not yet in common usage, and Knowlton's work represented an early demonstration of how the mosaic of squares could be controlled through computational logic to produce animated sequences.</p>
<h3>Mathematical Foundations and Algorithmic Exploration</h3>
<p>The pioneers of this era drew inspiration from mathematics, systems theory, and conceptual art movements that were emerging simultaneously. Vera Molnár, a Hungarian-born artist working in Paris, represents a crucial bridge between traditional artistic practice and computational methodology. Born in 1924, Molnár studied aesthetics and art history at the Budapest College of Fine Arts and began creating abstract geometrical and systematically determined paintings in the 1940s. By the late 1950s, she was iterating combinatorial images by hand using a methodology she termed her "machine imaginaire," manually working through all possible permutations of series according to self-imposed rules and limitations. In 1968, Molnár gained access to a computer at a Sorbonne research laboratory in Paris, where she taught herself Fortran, the early programming language that would become central to creative coding practice in this era. Using the binary language of zeros and ones, Molnár fed instructions into the computer that were output to a plotter, which produced line drawings with a moving pen. Her experimental work with variations of the letter M (evoking Malevich, Mondrian, and Molnár herself) demonstrated her conviction that there exists no single solution to an aesthetic problem, and she continued to explore serial variations within and across works while deliberately introducing what she termed a "1% disorder" to allow systematically determined factors of chance to influence the final artworks. Molnár's practice established the fundamental principle that algorithms could serve as generative systems that produce endless variations within bounded parameters, anticipating the explosion of generative art that would follow in subsequent decades.</p>
<h2>The 1970s: Expansion, Experimentation, and Conceptual Integration</h2>
<h3>The Emergence of Demoscene Precursors and Experimental Systems</h3>
<p>The 1970s witnessed a proliferation of creative coding practices across diverse platforms and contexts, with artists increasingly recognizing computational systems as essential to their aesthetic vocabularies.<sup class="citation"><a href="#ref-4" id="cite-4">4</a>,<a href="#ref-10" id="cite-10">10</a></sup> John Whitney Sr., widely regarded as one of the fathers of computer animation, shifted his practice to digital computers in the mid-1960s with a fellowship at IBM, working alongside physicist Jack Citron.<sup class="citation"><a href="#ref-10" id="cite-10">10</a></sup> Whitney's film Permutations (1968) and subsequent works demonstrated how digital computers with dedicated screens could control and display computational graphics in real time. The production process required every frame to be programmed and transferred onto punch cards, which produced instructions on magnetic tape that controlled a cathode ray tube to display each horizontal line of pixels while a movie camera filmed the results one frame at a time.<sup class="citation"><a href="#ref-10" id="cite-10">10</a></sup> Though the initial black-and-white results were later colorized by Robert Brown and Frank Olvey, this innovative process established a foundational technique for creating computational animation that would influence subsequent generations of digital artists.</p>
<p>Manfred Mohr, born in 1938 in Germany, wrote his first algorithm using Fortran IV in 1969, pioneering a systematic approach to algorithmic art that would define his six-decade career. Initially lacking access to automated drawing systems, Mohr plotted the results of his computer-generated data by hand in an exhausting and unsustainable process of intricate drafting. However, by autumn 1969, his future wife Estarose Wolfson, a mathematician, connected him to a laboratory in New York, and Mohr was able to generate his first truly computer-executed drawings, P-018 (1969), a series created with light beams directly onto photographic paper. This permitted Mohr to view multiple results generated from the same algorithm for the first time, fundamentally changing his understanding of what algorithmic art could accomplish. In early 1970, Mohr gained access to a Zuse pen plotter at the University of Darmstadt in Germany, and subsequently secured unique access to the computer center at the Météorologie Nationale in Paris, where he employed a high-resolution vector flatbed pen Benson plotter in conjunction with a CDC 6400 computer. In 1971, the Musée d'Art Moderne de la Ville de Paris presented "Manfred Mohr: Une Esthétique Programmée," the first solo exhibition of computer-generated digital art, featuring over twenty plotter drawings alongside demonstrations of his practice. The exhibition posed a provocative question to visitors: "What do you think of aesthetic research that is assisted by a computer?"—a question that remains contemporary and contested decades later.</p>
<h3>Institutional Recognition and Collaborative Innovation</h3>
<p>The 1970s saw increased collaboration between artists and computer engineers, particularly through organizations like Experiments in Art and Technology (EAT), founded by electrical engineer Billy Klüver at Bell Labs in 1966.<sup class="citation"><a href="#ref-4" id="cite-4">4</a></sup> Though EAT's origins preceded the 1970s, its influence expanded significantly during this decade as artists such as Andy Warhol, Robert Rauschenberg, Jean Tinguely, John Cage, and Jasper Johns engaged in complex collaborations with engineers and programmers. This collaborative framework established precedents for interdisciplinary creative practice that would become increasingly important as computational systems grew more sophisticated and specialized. The Whitney Museum of American Art has documented how artists throughout the 1970s and 1980s increasingly experimented with new computer-imaging techniques, evolving from the pen-plotter based drawings of earlier years toward video art, performance-based work, and real-time computational systems.<sup class="citation"><a href="#ref-4" id="cite-4">4</a></sup> This diversification marked a fundamental shift in how creative coding could be conceptualized—no longer confined to the generation of static drawings but expanding into temporal, interactive, and performative domains.</p>
<h3>Game of Life and Cellular Automata</h3>
<p>One of the most influential conceptual frameworks emerging during this period was John Conway's Game of Life, published in 1970 in Scientific American, which demonstrated how simple rule-based systems could generate extraordinarily complex emergent behaviors. Though not strictly a visualization created through traditional programming, Conway's cellular automaton became foundational to understanding how computational rules could produce unpredictable and aesthetically compelling results from deterministic initial conditions. The Game of Life established principles that would influence generative artists for decades: the notion that simple rules applied iteratively could produce patterns of surprising complexity, that observer-independent dynamics could emerge from local interactions, and that computational systems could model natural phenomena while simultaneously producing abstract aesthetic forms. The philosophical implications were profound—Conway designed the rules carefully with the intent of making the system's evolution unpredictable, creating a state space where the observer's curiosity about what would happen next became a central feature of the aesthetic experience.</p>
<h2>The 1980s and Early 1990s: The Demoscene, Commercialization, and the Rise of Personal Computing</h2>
<h3>The Demoscene Emerges as a Global Phenomenon</h3>
<p>The demoscene, an international computer art subculture focused on producing demos—self-contained, sometimes extremely small computer programs that generate audiovisual presentations—originated in the 1980s, fundamentally reshaping how creative coding was practiced, exhibited, and valued.<sup class="citation"><a href="#ref-8" id="cite-8">8</a></sup> The scene began with the home computer revolution and the subsequent advent of software cracking, as programmers who modified game code to remove copy protection began adding introduction screens ("cracktros") as signatures, gradually evolving these into increasingly sophisticated visual presentations.<sup class="citation"><a href="#ref-8" id="cite-8">8</a></sup> The earliest crack screens appeared on the Apple II in the early 1980s, often consisting merely of text crediting the cracking group, but gradually transformed into animated sequences with increasingly impressive visual effects and musical accompaniment.<sup class="citation"><a href="#ref-8" id="cite-8">8</a></sup> The Dutch groups 1001 Crew and The Judges, both working on the Commodore 64, are often credited as among the earliest demo groups, competing with each other in 1986 by producing pure demos with original graphics and music involving extensive hardware trickery.<sup class="citation"><a href="#ref-8" id="cite-8">8</a></sup> Future Crew, active in the early 1990s, became legendary within the demoscene for groundbreaking demos like "Unreal" (1992) and "Second Reality" (1993), which demonstrated advanced programming, visual artistry, and music composition, setting new standards for what was possible in real-time computer graphics. These works inspired countless artists and programmers worldwide, establishing the demoscene as a parallel track to institutional art contexts within which creative coding flourished.</p>
<p>The period from 1986 through the mid-1990s is often referred to as the "Golden Age of the Demoscene," characterized by a surge of creativity and innovation as home computers like the Commodore 64, Amiga, and Atari ST became increasingly accessible and powerful.<sup class="citation"><a href="#ref-8" id="cite-8">8</a></sup> The scene developed its own competitive infrastructure, with "demoparties" emerging as festivals where groups released and premiered new works, which were then voted upon by the community.<sup class="citation"><a href="#ref-8" id="cite-8">8</a></sup> Competition drove technical innovation, with early competitions focused on metrics like the number of "bobs" (blitter objects) on screen per frame or the number of DYCP (Different Y Character Position) scrollers possible on a Commodore 64.<sup class="citation"><a href="#ref-8" id="cite-8">8</a></sup> The Amiga's Advanced Graphics Architecture (AGA), introduced with the Amiga 1200 and 4000 computers in 1992, represented a significant leap in capabilities, expanding the color palette from 4,096 to 16.8 million colors and supporting higher screen resolutions, creating new possibilities for demoscene productions. The demoscene's emphasis on extreme optimization, often compressing entire elaborate audiovisual experiences into 4-kilobyte executable files (known as "4K demos"), pushed programmers to develop innovative compression techniques and rendering algorithms that would later influence commercial game development and professional graphics programming.</p>
<h3>Technical Innovation and Hardware Trickery</h3>
<p>The demoscene's technical achievements during this period centered on exploiting hardware capabilities in ways that manufacturers had not explicitly intended, creating visual effects that appeared to exceed the theoretical specifications of machines like the Commodore 64 and Amiga.<sup class="citation"><a href="#ref-8" id="cite-8">8</a></sup> Programmers developed "hardware trickery" techniques that manipulated video timing, exploited cache behavior, and employed counter-intuitive approaches to achieve real-time rendering of complex visual phenomena. These techniques represented a form of intimate knowledge about computational systems—understanding not merely what a computer was theoretically capable of, but how its actual implementation could be pushed beyond documented parameters. This culture of extreme optimization and creative constraint-based problem-solving would later influence how developers approached mobile computing, web-based graphics, and other resource-constrained environments where creative solutions became necessary.</p>
<h2>The 1990s and Early 2000s: Democratization through Processing and Open-Source Movements</h2>
<h3>The Development of Processing: Making Code Accessible</h3>
<p>The turning point in the democratization of creative coding came with the initiation of the Processing project in 2001 by Casey Reas and Ben Fry, both formerly of the Aesthetics and Computation Group at the MIT Media Lab. Processing was conceived as a free graphics library and integrated development environment specifically designed for the electronic arts, new media art, and visual design communities, with the explicit purpose of teaching non-programmers the fundamentals of computer programming within a visual context. The project drew significant inspiration from earlier work at the MIT Media Lab, particularly from the Visual Language Workshop led by Muriel Cooper and Design By Numbers led by John Maeda.<sup class="citation"><a href="#ref-9" id="cite-9">9</a></sup> While Design By Numbers had provided a minimalist coding environment, its limitations—including fixed canvas size and grayscale output—constrained its utility for visual artists. Processing built upon Design By Numbers's strengths while eliminating these constraints, allowing users to work with color, larger canvases, and even three-dimensional graphics.<sup class="citation"><a href="#ref-9" id="cite-9">9</a></sup> The developers emphasized simplicity, offering a minimalist interface that encouraged users to begin coding without feeling overwhelmed by technical details, and this approachability contributed significantly to the platform's rapid adoption.</p>
<p>What distinguished Processing from earlier creative coding frameworks was its explicit commitment to democratization: the software was completely open-source, free to use, and the developers actively encouraged sharing of both the software and works created with it through the internet.<sup class="citation"><a href="#ref-9" id="cite-9">9</a></sup> Initially attracting a relatively small user base, the community grew exponentially as various forums and platforms emerged, providing spaces for users to discuss their work, seek help, and share creations.<sup class="citation"><a href="#ref-9" id="cite-9">9</a></sup> Among the most influential early artists working with Processing was Casey Reas himself, whose project "Process Compendium" (2004-2010) explored generative art by defining simple elements and behaviors that interact to produce dynamic, evolving visuals guided by descriptive text that leaves space for interpretation.<sup class="citation"><a href="#ref-9" id="cite-9">9</a></sup> Jared S. Tarbell began working with Processing in the early 2000s, developing abstract geometric artworks that blended mathematical elegance with artistic precision.<sup class="citation"><a href="#ref-9" id="cite-9">9</a></sup> His most iconic work, "Substrate" (2003), exemplifies the principle that astonishingly complex visual results can emerge from elegantly simple algorithmic rules: the algorithm consists of just two rules—lines grow straight until they hit another line or the canvas edge, and new lines form at right angles to existing lines. When executed, this simple system generates intricate patterns resembling urban street grids or cracks in dried earth, demonstrating how iterative local rules produce complex global structures. Tarbell's philosophical approach emphasized that the best algorithms are those whose semantics can be easily understood or described, as the viewer gains deeper appreciation for the resulting images when they comprehend the underlying simplicity generating the complexity.</p>
<h3>Perlin Noise and Procedural Texture Generation</h3>
<p>Ken Perlin, working at New York University, developed Perlin noise in 1982 as a response to his frustration with the "machine-like" appearance of computer-generated imagery in early films like Tron. Perlin formally described his findings in a SIGGRAPH paper in 1985 titled "An Image Synthesizer," establishing a technique that has become fundamental to procedural content generation across all domains of computer graphics. The algorithm generates pseudo-random gradients and interpolates between them to produce natural-appearing textures, with the crucial property that all visual details remain approximately the same size, making the output readily controllable. Multiple scaled copies of Perlin noise can be layered together to create fractals and fractal brownian motion, producing highly realistic procedural textures for surfaces, fire, smoke, and clouds. In recognition of this innovation, Perlin was awarded an Academy Award for Technical Achievement in 1997, with the citation reading: "To Ken Perlin for the development of Perlin Noise, a technique used to produce natural appearing textures on computer generated surfaces for motion picture visual effects." Notably, Perlin did not apply for patents on the algorithm, though he was later granted a patent for three-dimensional implementations using simplex noise in 2001. Simplex noise offers similar functionality to Perlin noise but uses a simpler space-filling grid, alleviating some computational complexity and visual artifacts associated with the original formulation.</p>
<h3>Fractals and Natural Phenomena Visualization</h3>
<p>The visualization of fractal geometry emerged as another major category of creative coding practice during this period. Loren Carpenter, a Boeing engineer, created "Vol Libre," a two-minute color film presented at SIGGRAPH in 1980, demonstrating the first application of fractals in computer-generated imagery. After reading Benoît Mandelbrot's 1977 book "Fractals: Form, Chance and Dimension," which described geometry of natural rough rather than smooth shapes, Carpenter developed software for rendering realistic mountains and landscapes using fractal geometry. Each frame of the film required twenty to forty minutes of computing time on a VAX-11/780 computer, representing a massive computational investment for the era. The film's presentation reportedly caused the entire audience to rise to their feet in astonishment—the realistic landscapes and flying camera movements represented a fundamental breakthrough in computational aesthetics. Ed Catmull, a legendary figure in computer graphics, walked up to Carpenter after the film and offered him a position at Lucasfilm, which Carpenter accepted immediately, beginning his involvement with the team that would eventually become Pixar. The demonstration established that fractal-based procedural generation could produce visually compelling natural phenomena that appeared indistinguishable from photographic reality, fundamentally changing expectations about what computational systems could visualize.</p>
<h3>Harmonographs and Mechanical-Computational Synthesis</h3>
<p>The harmonograph, a mechanical device using pendulum motion to trace geometric designs, represents a fascinating category of creative coding visualization that bridges mechanical and computational domains. These devices, employing two or more pendulums connected to a drawing mechanism, produce patterns determined by the frequencies, amplitudes, phases, and damping characteristics of the oscillating systems. Contemporary artists have recreated harmonograph behavior computationally, recognizing that the mathematical equations governing pendulum motion (involving sinusoidal components and exponential damping) can be faithfully rendered through code. The beauty of harmonographs lies in their capacity to generate intricate, mathematically determined patterns while maintaining an organic, naturalistic appearance—a balance that has appealed to artists across centuries. When programmed computationally, harmonographs generate images through iterations of equations containing sine functions, allowing parameter adjustment to explore the space of possible patterns. By maintaining specific ratios between frequencies (such as 3:2, 4:5, 4:3, or 5:4), particularly beautiful patterns emerge, and introducing small deviations from these ratios produces surprising variations. The computational implementation permits real-time visualization, allowing artists to observe the pattern tracing as if watching a physical harmonograph execute—a visualization method that reveals the underlying mathematical structure more clearly than static final images alone.</p>
<h2>The 2000s: Expansion into Web, Mobile, and Real-Time Graphics</h2>
<h3>The Rise of Web-Based Creative Coding</h3>
<p>The emergence of web technologies as platforms for creative coding represented a fundamental democratization, making computational art accessible to anyone with a browser rather than requiring specialized software installation. Processing.js, a JavaScript port of Processing initiated in 2008 by John Resig and maintained through a partnership between the Mozilla Foundation and Seneca College, enabled existing Processing Java code to run on the web. This transition meant that artists could share interactive works directly through URLs, lowering barriers to both creation and distribution. The period also saw the emergence of p5.js in 2013, created by Lauren McCarthy as a native JavaScript alternative to Processing.js with official support from the Processing Foundation, which eventually gained over 1.5 million users.</p>
<h3>openFrameworks and Advanced Real-Time Graphics</h3>
<p>Parallel to Processing's development, Zach Lieberman and collaborators created openFrameworks beginning around 2004-2005, an open-source C++ toolkit for creative coding designed to provide lower-level access to computational systems while maintaining artist-friendly interfaces. Lieberman, teaching at Parsons School of Design while working as an artist creating interactive projects with code, recognized that C++ offered access to computer vision, sound processing, hardware interaction, and extensive libraries of tools while avoiding some of the limitations of Processing's Java-based approach. The philosophy behind openFrameworks emphasized joy and community-driven development, with the creators stressing the importance of creating a friendly atmosphere around programming, which could otherwise be an unfriendly and isolating activity. openFrameworks attracted artists like Theo Watson and Arturo Castro, who contributed OS X and Linux versions respectively, and the framework gained institutional recognition when winning a prize at Ars Electronica in 2008.</p>
<h3>Shader Programming and GPU-Accelerated Graphics</h3>
<p>During this period, shader programming emerged as a powerful domain for real-time computational graphics, enabling programmers to harness the computational power of Graphics Processing Units (GPUs) for visual expression. Shaders—small programs that run on GPU hardware to determine the color and appearance of pixels—allow artists to create stunning visual effects impossible to achieve through CPU-based computation alone. Inigo Quilez, widely recognized as one of the leading figures in shader programming and co-creator of the Shadertoy website, has been instrumental in establishing shader programming as an artistic medium. Shadertoy, launched as a collaborative platform for interactive shader programming, allows users to write shaders directly in a web browser, share their work with the community, and study other artists' implementations. The platform has become central to shader art culture, with artists creating increasingly sophisticated 3D renderers, procedural pattern generators, and animated visual experiences entirely through GPU-executed code. Ray marching, a technique related to but distinct from traditional ray tracing, emerged as a fundamental tool for creating realistic 3D scenes in real-time through shader code.</p>
<h2>The 2010s: Algorithmic Art, Data Visualization, and the Emergence of NFT Generative Art</h2>
<h3>Harold Cohen and AARON: The Long-Haul Algorithmic System</h3>
<p>Harold Cohen, an established painter in London who transitioned to computational art beginning in the late 1960s, deserves particular attention for his long-term commitment to exploring how computers could participate in artistic creation. Conceiving what he termed a "collaboration" with the computer, Cohen created AARON, initially developed in the late 1960s at the University of California, San Diego and named in the early 1970s. The title alludes to the biblical figure anointed as speaker for his brother Moses, challenging assumptions about artistic creation as divinely inspired communication. AARON began as a relatively simple system where Cohen defined a small set of rules and forms that the computer composed into drawings, which were then output to paper using a drawing "turtle"—a small robot equipped with a marker. The early versions dealt exclusively with internal aspects of human cognition, attempting to identify functional primitives and differentiations used in building mental images and consequently in making drawings and paintings. The system could differentiate between figure and ground, inside and outside, and function in terms of similarity, division, and repetition—without any object-specific knowledge of the external world.</p>
<p>Over decades of development, Cohen refined AARON's knowledge base, adding more rules and forms including everyday objects, plants, and eventually people, though he would occasionally remove forms when they proved inconsistent with his research goals. The system evolved through numerous iterations, with early outputs consisting of black and white drawings that Cohen would sometimes hand-color, through to later versions where the system itself could color its outputs using a robotic painting arm nearly eight feet long and six feet wide that held paper via vacuum table while drawing and coloring forms. The philosophical question of who constituted the artist—Cohen or AARON—became a persistent theme in his practice. He compared the relationship to that between Renaissance painters and their studio assistants, arguing that AARON did precisely what human artists did: taking knowledge of forms and applying them to the creation process. Though AARON never demonstrated self-improvement (which Cohen noted as a definitive marker of machine intelligence), the system's capacity to generate thousands of unique drawings raised fundamental questions about authorship, intentionality, and the role of the artist when machines participate in creation.</p>
<h3>Data Visualization and Information Aesthetics</h3>
<p>The 2010s witnessed an explosion of creative coding directed toward visualizing abstract data, treating information as a material to be aesthetically shaped. Martin Wattenberg transformed diverse datasets—from musical scores to Wikipedia edit histories—into dramatic visual compositions. His project "Shape of Song" (2001) visualized the structure of musical compositions, mapping recurring themes as arcs that reveal structural patterns otherwise invisible in listening alone. "History Flow" (2003), created with Fernanda Viegas, visualized the temporal evolution of Wikipedia articles, representing edit history as colored streams that illuminate patterns of collaborative knowledge construction and occasional vandalism. These works demonstrated that computational visualization could simultaneously serve informational and aesthetic functions, creating works that educated while inspiring wonder.</p>
<h3>The Rise of Live Coding and Performative Computation</h3>
<p>Live coding emerged as a genre of creative practice in which artists write code in real-time during performances, with the code and its output both visible to audiences. Combining elements of live programming, VJing, and performance art, live coding practitioners like those at Algoraves (algorithmic raves) compose and execute code live to generate synchronized visual and musical content. The practice emphasizes transparency—viewers see the code being typed, understand (at least partially) the relationship between code and output, and experience the instantaneous feedback loop that defines the medium. This transparency contrasts with traditional VJing, which involves manipulating pre-existing video content, or conventional musical instrument performance where the relationship between physical gesture and sound can be less direct. The live coding community developed specialized tools and frameworks, with CJing (combining creative coding and VJing) emerging as a hybrid practice using environments like Visor, a live coding environment for producing graphics in audiovisual performances.</p>
<h3>Art Blocks and the First Wave of Generative NFTs</h3>
<p>The emergence of blockchain technology and Non-Fungible Tokens (NFTs) in the late 2010s and early 2020s created entirely new contexts for generative art practice, fundamentally altering how computational artworks could be created, distributed, owned, and valued. Erick "Snowfro" Calderon launched Art Blocks in November 2020, a platform enabling artists to create generative art collections to be minted as NFTs on the Ethereum blockchain. The revolutionary aspect of Art Blocks involved requiring that all source code and algorithms be finalized and placed on the blockchain permanently, without any ability to alter the code after deployment. This constraint forced artists to accept every output of their algorithm as their signed piece, unable to cherry-pick favorable outputs for publication as traditional generative artists had previously done. As one early Art Blocks artist reflected, this requirement elevated algorithmic execution because artists had to ensure their systems could generate work they felt proud of across all possible parameter combinations, not merely the most aesthetically pleasing instances.</p>
<p>Among the most significant early Art Blocks collections was "Fidenza" by Tyler Hobbs, released in October 2021, featuring vibrant, flowing compositions generated by algorithms exploring the interplay of curves and colors. "Ringers" by Dmitri Cherniak, released in January 2021, explored the mathematical problem of how a looped string can wrap around a set of pegs, generating endlessly varied configurations. The collection's immediate market success—selling out in approximately twenty minutes with secondary market sales reaching over 640 ETH (roughly $1 million) within three weeks—demonstrated explosive collector interest in generative art as a cultural and economic phenomenon. The most famous single generative artwork emerged from Ringers: "Ringers #879," nicknamed "The Goose," achieved legendary status through a combination of unique aesthetic qualities and dramatic secondary market activity, eventually selling for $6.2 million at Sotheby's in June 2023 after Three Arrows Capital's 2022 financial collapse. In a watershed moment for institutional recognition of generative art as culturally significant, the Los Angeles County Museum of Art (LACMA) acquired "Ringers #962" in 2023, cementing generative art's place within mainstream art institutions and collections.</p>
<h2>The 2020s: Consolidation, Institutional Integration, and Technical Sophistication</h2>
<h3>Contemporary Creative Coding Toolkits and Frameworks</h3>
<p>The landscape of creative coding tools in the 2020s reflects decades of accumulated knowledge about making computation accessible while maintaining expressive power.<sup class="citation"><a href="#ref-1" id="cite-1">1</a>,<a href="#ref-9" id="cite-9">9</a></sup> Contemporary frameworks include Cinder, a C++ library for programming with aesthetic intent across graphics, audio, video, and computational geometry domains; Max MSP, a visual programming language for music and multimedia; openFrameworks; OPENRNDR, a Kotlin-based creative coding framework; p5.js and Processing; Pure Data; Shoebot; and numerous specialized tools for particular practices.<sup class="citation"><a href="#ref-1" id="cite-1">1</a></sup> These tools collectively represent a mature ecosystem enabling practitioners from diverse backgrounds—professional artists, students, hobbyists, and researchers—to engage in computational creativity with appropriate levels of abstraction.</p>
<p>The diversity of available programming languages reflects pragmatic recognition that different contexts favor different technical approaches. Python's emergence as a preferred language for generative artists reflects its accessibility and the availability of specialized libraries like generativepy for creating visual generative art and mathematical diagrams.<sup class="citation"><a href="#ref-1" id="cite-1">1</a></sup> JavaScript-based approaches like p5.js and Three.js remain dominant for web-based creation and display. Rust, through frameworks like Nannou, appeals to artists prioritizing performance and systems-level control.<sup class="citation"><a href="#ref-1" id="cite-1">1</a></sup> The proliferation of language choices and tool availability suggests a mature field where practitioners can select frameworks aligned with their specific needs, aesthetics, and technical comfort levels.</p>
<h3>Advanced Rendering Techniques and 3D Graphics</h3>
<p>Contemporary creative coding frequently employs sophisticated 3D rendering techniques that would have been computationally unimaginable in earlier decades. Three-dimensional Gaussian Splatting, an emerging technique for representing 3D scenes through millions of Gaussian functions optimized through adaptive density control, enables real-time rendering of photorealistic three-dimensional scenes with high visual quality and efficient GPU utilization. Unlike earlier 3D rendering approaches like MipNeRF360 or Plenoxels, Gaussian Splatting captures larger scenes with minimal artifacts and enables real-time navigation and interaction with detailed three-dimensional environments. Tessellation techniques, including adaptive tessellation of subdivision surfaces, allow detailed geometric representations while minimizing computational overhead by allocating computational resources to visible regions requiring finer geometric detail. These technical developments represent the contemporary frontier of computational visualization, enabling artists to create increasingly sophisticated real-time interactive experiences.</p>
<h3>Shader Art and Procedural Graphics in the Contemporary Moment</h3>
<p>Shader programming has evolved into a full creative discipline with communities, competitions, and recognized master practitioners. Shadertoy continues to serve as the central platform where shader artists share work, study techniques, and collaborate across global networks. The technical sophistication visible in contemporary shader art—photorealistic renderings of complex three-dimensional environments, intricate fractal visualizations, and animated procedural patterns—demonstrates the maturity of GPU-accelerated graphics as a medium for artistic expression. Tutorials from artists</p>
    </article>
    
    <section class="citations" id="citations">
        <h2>Sources</h2>
        <ol>
            <li id="ref-1">
        <a href="#cite-1" class="back-ref" title="Back to text">↩</a>
        <a href="https://en.wikipedia.org/wiki/Creative_coding" target="_blank" rel="noopener">[1] https://en.wikipedia.org/wiki/Creative_coding</a>
    </li>
<li id="ref-2">
        <a href="#cite-2" class="back-ref" title="Back to text">↩</a>
        <a href="https://www.dirtalleydesign.com/blogs/news/programming-numbers-and-art-making-generative-designs" target="_blank" rel="noopener">[2] https://www.dirtalleydesign.com/blogs/news/programming-numbers-and-art-making-generative-designs</a>
    </li>
<li id="ref-3">
        <a href="#cite-3" class="back-ref" title="Back to text">↩</a>
        <a href="https://collections.vam.ac.uk/item/O221321/schotter-print-nees-georg/" target="_blank" rel="noopener">[3] https://collections.vam.ac.uk/item/O221321/schotter-print-nees-georg/</a>
    </li>
<li id="ref-4">
        <a href="#cite-4" class="back-ref" title="Back to text">↩</a>
        <a href="https://whitney.org/essays/histories-of-the-digital-now" target="_blank" rel="noopener">[4] https://whitney.org/essays/histories-of-the-digital-now</a>
    </li>
<li id="ref-5">
        <a href="#cite-5" class="back-ref" title="Back to text">↩</a>
        <a href="https://10print.org/10_PRINT_121114.pdf" target="_blank" rel="noopener">[5] https://10print.org/10_PRINT_121114.pdf</a>
    </li>
<li id="ref-6">
        <a href="#cite-6" class="back-ref" title="Back to text">↩</a>
        <a href="https://zellyn.com/2024/06/schotter-1/" target="_blank" rel="noopener">[6] https://zellyn.com/2024/06/schotter-1/</a>
    </li>
<li id="ref-7">
        <a href="#cite-7" class="back-ref" title="Back to text">↩</a>
        <a href="https://www.historyofinformation.com/detail.php?id=3260" target="_blank" rel="noopener">[7] https://www.historyofinformation.com/detail.php?id=3260</a>
    </li>
<li id="ref-8">
        <a href="#cite-8" class="back-ref" title="Back to text">↩</a>
        <a href="https://en.wikipedia.org/wiki/Demoscene" target="_blank" rel="noopener">[8] https://en.wikipedia.org/wiki/Demoscene</a>
    </li>
<li id="ref-9">
        <a href="#cite-9" class="back-ref" title="Back to text">↩</a>
        <a href="https://www.katevassgalerie.com/blog/processing" target="_blank" rel="noopener">[9] https://www.katevassgalerie.com/blog/processing</a>
    </li>
<li id="ref-10">
        <a href="#cite-10" class="back-ref" title="Back to text">↩</a>
        <a href="https://www.amygoodchild.com/blog/computer-art-50s-and-60s" target="_blank" rel="noopener">[10] https://www.amygoodchild.com/blog/computer-art-50s-and-60s</a>
    </li>
        </ol>
    </section>
    <footer>filed under: things worth knowing</footer>
</body>
</html>